This study proposes a novel approach for the classification of melanoma medical images by combining two powerful neural network architectures, namely CNNs and ViTs. CNNs are traditionally effective in extracting spatial features, while ViTs are distinguished by their ability to capture global relationships between pixels. By integrating these two paradigms, our model benefits from a more comprehensive representation of the discriminative features present in melanoma images. Experimental results demonstrate a significant improvement in performance compared to approaches based solely on CNNs or ViTs. This hybrid approach opens new and promising avenues for more accurate melanoma detection in medical images, thus offering considerable potential for early diagnosis and clinical management. A simple way to remember the common features of melanoma is to think in alphabetical order â€“ the ABCDEs of melanoma. ABCDE stands for asymmetry, border, color, diameter, and evolution. These are the characteristics of skin lesions that physicians look for when diagnosing and classifying melanoma. The melanoma medical image classification project is based on an innovative solution combining the advantages of convolutional neural networks (CNNs) and vision transformers (ViTs). The main objective is to develop an automated diagnostic tool for the early detection of melanoma from dermatoscopic images. The model architecture combines the ability of CNNs to extract local features with the power of ViTs to capture global relationships, thus improving the model's ability to handle the variability of medical images. This project thus represents a significant contribution to the improvement of automated dermatological diagnoses, combining the latest technological advances with rigorous medical practices.
